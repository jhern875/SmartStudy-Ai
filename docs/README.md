# SmartStudy AI ğŸ“šâœ¨

A powerful AI-powered study assistant that helps you analyze documents, generate summaries, create flashcards, and build interactive quizzes. Built with React.js frontend and Node.js backend, powered by local AI models.

## ğŸš€ Features

- **ğŸ“„ Document Upload & Processing**: Support for PDF, DOCX, and TXT files
- **ğŸ¤– AI-Powered Analysis**: Generate summaries, important terms, and concept graphs
- **â“ Interactive Quiz Generation**: Create Quizlet-style questions with answers
- **ğŸ“Š Concept Visualization**: Visual concept graphs from document content
- **ğŸ’¾ Results Management**: Save, export, and manage your study materials
- **ğŸ—‘ï¸ File Management**: Upload, delete, and organize your documents
- **ğŸ¨ Modern UI**: Beautiful, responsive interface with smooth animations

## ğŸ› ï¸ Tech Stack

### Frontend
- **React.js** - Modern UI framework
- **CSS3** - Custom styling with gradients and animations
- **JavaScript ES6+** - Modern JavaScript features

### Backend
- **Node.js** - Server runtime
- **Express.js** - Web framework
- **Multer** - File upload handling
- **PDF-Parse** - PDF text extraction
- **Mammoth** - DOCX text extraction

### AI Integration
- **Ollama** - Local AI model server
- **LLaMA 2 / Gemma3** - Large Language Models
- **Custom AI Service** - Tailored prompts for study materials

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** (v16 or higher) - [Download here](https://nodejs.org/)
- **npm** (comes with Node.js)
- **Ollama** - [Download here](https://ollama.ai/)

## ğŸš€ Installation & Setup

### 1. Clone the Repository

```bash
git clone <repository-url>
cd SmartStudy-Ai
```

### 2. Install Ollama

#### Windows
```bash
# Download from https://ollama.ai/
# Run the installer and follow the setup wizard
```

#### macOS
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 3. Download AI Models

```bash
# Start Ollama (if not already running)
ollama serve

# Download the AI model (in a new terminal)
ollama pull llama2
# OR
ollama pull gemma3
```

### 4. Install Dependencies

#### Backend Dependencies
```bash
cd backend
npm install
```

#### Frontend Dependencies
```bash
cd Frontend
npm install
```

### 5. Configure Environment

Create a `.env` file in the `backend` directory:

```bash
cd backend
# Create .env file (optional - app works without it)
touch .env
```

### 6. Start the Application

#### Terminal 1 - Start Backend
```bash
cd backend
npm start
```
Backend will run on: http://localhost:5000

#### Terminal 2 - Start Frontend
```bash
cd Frontend
npm start
```
Frontend will run on: http://localhost:3000

#### Terminal 3 - Ensure Ollama is Running
```bash
ollama serve
```

## ğŸ¯ Quick Start Guide

1. **Open your browser** and go to http://localhost:3000
2. **Upload a document** (PDF, DOCX, or TXT)
3. **Select your document** from the document selection page
4. **Choose an AI feature**:
   - ğŸ“ **Summary**: Get a concise summary
   - â“ **Questions/Quiz**: Generate Quizlet-style questions
   - ğŸ“š **Important Terms**: Extract key terms and definitions
   - ğŸ§  **Concept Graph**: Visualize document concepts
5. **Interact with results** and export as needed

## ğŸ“ Project Structure

```
SmartStudy-Ai/
â”œâ”€â”€ backend/                 # Node.js backend server
â”‚   â”œâ”€â”€ models/             # AI model configurations
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â”‚   â”œâ”€â”€ ai.js          # AI feature routes
â”‚   â”‚   â””â”€â”€ upload.js      # File upload routes
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â””â”€â”€ aiService.js   # AI integration service
â”‚   â”œâ”€â”€ uploads/           # Uploaded files storage
â”‚   â”œâ”€â”€ server.js          # Main server file
â”‚   â””â”€â”€ package.json       # Backend dependencies
â”œâ”€â”€ Frontend/              # React.js frontend
â”‚   â”œâ”€â”€ public/            # Static files
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ pages/         # Page components
â”‚   â”‚   â”œâ”€â”€ services/      # API service layer
â”‚   â”‚   â””â”€â”€ styles/        # CSS stylesheets
â”‚   â””â”€â”€ package.json       # Frontend dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

### AI Model Selection

The app uses Ollama with LLaMA 2 or Gemma3. To change models:

1. **Download a different model**:
   ```bash
   ollama pull llama2:7b
   # OR
   ollama pull gemma3:2b
   ```

2. **Update the model in** `backend/services/aiService.js`:
   ```javascript
   const model = 'llama2'; // or 'gemma3'
   ```

### Port Configuration

- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:5000
- **Ollama**: http://localhost:11434

To change ports, modify the respective configuration files.

## ğŸš€ Usage Examples

### Generate Questions from a Document

1. Upload a PDF document about machine learning
2. Select the document from the list
3. Choose "Questions/Quiz" feature
4. Get 5 interactive questions with answers
5. Use "Generate New Questions" for more variety

### Create Concept Graphs

1. Upload a research paper
2. Select "Concept Graph" feature
3. View visual representation of key concepts
4. Export the graph for presentations

### Extract Important Terms

1. Upload a textbook chapter
2. Choose "Important Terms" feature
3. Get a list of key terms with definitions
4. Export as flashcards for study

## ğŸ› Troubleshooting

### Common Issues

#### "Ollama command not found"
- Ensure Ollama is installed and in your PATH
- Restart your terminal/command prompt
- On Windows, restart your computer after installation

#### "Model not found"
```bash
# Download the required model
ollama pull llama2
# OR
ollama pull gemma3
```

#### "Backend connection failed"
- Ensure backend is running on port 5000
- Check that Ollama is running on port 11434
- Verify no firewall blocking the connections

#### "Frontend not loading"
- Ensure frontend is running on port 3000
- Check browser console for errors
- Verify all dependencies are installed

### Performance Tips

- **Use smaller models** for faster responses (gemma3:2b)
- **Limit document size** for better performance
- **Close other applications** to free up memory
- **Use SSD storage** for faster file processing

## ğŸ“ API Documentation

### Backend Endpoints

- `GET /api/health` - Health check
- `GET /api/documents` - List uploaded documents
- `POST /api/upload` - Upload a file
- `POST /api/ai/summarize` - Generate summary
- `POST /api/ai/questions` - Generate questions
- `POST /api/ai/terms` - Extract important terms
- `POST /api/ai/concepts` - Generate concept graph
- `DELETE /api/documents/:filename` - Delete document

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Ollama** for local AI model hosting
- **React.js** for the frontend framework
- **Express.js** for the backend framework
- **OpenAI** for inspiration in AI integration

## ğŸ“ Support

If you encounter any issues:

1. Check the troubleshooting section above
2. Review the console logs for error messages
3. Ensure all prerequisites are installed
4. Verify all services are running

---

**Happy Studying! ğŸ“šâœ¨** 